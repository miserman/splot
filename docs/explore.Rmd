---
title: "Exploring Data with splot"
output: rmarkdown::html_document
vignette: >
  %\VignetteIndexEntry{Exploring Data with splot}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

This example looks at a few different results from a set of studies: <a href="https://osf.io/963gp/" target="_blank">osf.io/963gp</a>.

*Built with R 
`r getRversion()`
on 
`r format(Sys.time(),'%B %d %Y')`*

***
# Setting up

First, be sure splot is loaded:
```{r}
library('splot')
```

You can read in the data directly from OSF:
```{r}
data = read.csv('https://osf.io/crgkn/?action=download')
```

or download the file: <a href='https://osf.io/crgkn/?action=download' target='_blank'>osf.io/crgkn</a>

Then have a look at the data. These are participant and condition related variables, which will be particularly useful for splitting:
```{r}
data[493:502, c(1:3,80:82)]
```

***
# Calculating Language Style Matching (LSM)

Each of these studies had participants reading a prompt and writing advice in response. The language from both the prompts and responses were analyzed with the Linguistic Inquiry and Word Count (<a href='https://liwc.wpengine.com/' target='_blank'>LIWC</a>) program, which categorizes words based on its dictionary. Using these categories, we can look at forms of language style matching---how similar participants' reply is to the prompt they read.

First, the prompts and their LIWC categories are included in a separate file:
```{r}
prompts = read.csv('https://osf.io/xm6ew/?action=download')
```

Each of the strings in prompts' `Type` variable corresponds to the topic, style, and study of each participant's reply. We want to compare the language style of each prompt to its replies, so we'll make a Type variable to match in data:
```{r}
data$Type = paste0(
  ifelse(data$Topic=='Relational', 'R', 'LC'),
  ifelse(data$Style=='Feminine', 'F', 'M'),
  data$Study
)
```

Now we can actually calculate LSM. A Standard LSM calculation (from <a href='http://sml.comm.cornell.edu/wordpress/wp-content/uploads/2013/12/Gonzales-Hancock-Pennebaker-2010-Language-style-matching-as-a-predictor-of-social-dynamics-in-small-groups.pdf' target='_blank'>Gonzales, Hancock, & Pennebaker, 2009</a>) uses 9 LIWC function word categories. We'll save these names to easily identify them in each dataset:
```{r}
cats = c('ppron','ipron','article','adverb','conj','prep','auxverb','negate','quant')
```

This form of LSM uses inversed Canberra distance as a measure of similarity, but there are many similarity metrics, so we might compare a few:
```{r}
#name the metrics we want to calculate.
metrics = c('Canberra','Cosine','Euclidean')

#make empty columns for each in the dataset.
data[,metrics] = NA

#then loop through each condition.
for(c in unique(data$Type)){
  
  #pull in the prompt for the given condition.
  comp = prompts[prompts$Type==c, cats]
  
  #identify the subset of data replying to this prompt.
  su = data$Type==c
  
  #then perform each calculation between each row in data and the prompt.
  data[su, metrics] = t(apply(data[su, cats], 1, function(r)c(
    sum(1-abs(r-comp)/(r+comp+.0001))/length(r),
    sum(r*comp)/sum(r^2*sum(comp^2))^.5,
    1/(1+sum((r-comp)^2)^.5)
  )))

}
```

With the new variables added, we can attach the data:
```{r}
attach(data)
```

***
# Looking at Language Style Matching

First, we can look at distributions in a few different ways:
```{r, fig.height=3, fig.width=10, dev='CairoSVG'}
splot(data[,metrics])
```
```{r, fig.height=3, fig.width=10, dev='CairoSVG'}
#mv.scale z-scores multiple y variables to make them easier to compare.
splot(data[,metrics], mv.scale=T)
```
```{r, fig.height=3, fig.width=10, dev='CairoSVG'}
#su subsets the dataset to show only replies to the masculine relational prompt in Study 4.
splot(data[,metrics], mv.scale=T, su=Type=='RM4')
```

The different similarity metrics we calculated a pretty highly correlated:
```{r}
cor(data[,metrics])
```

But their relationship is not quite linear:
```{r, fig.height=5, fig.width=10, dev='CairoSVG'}
#cbind (or list) is another way to enter multiple y variables.
#when a transformed version of the x variable is added, it is used to adjust the prediction line.
splot(cbind(Canberra, Cosine)~Euclidean+log(Euclidean))
```

They also vary differently between prompts and studies:
```{r, fig.height=6, fig.width=11.5, dev='CairoSVG'}
splot(data[,metrics]~prompt, between=Study, su=Study>2, mv.scale=T)
```

In Studies 3 and 4, each participant replied to two prompts, so we can look at changes in their matching from one prompt to another (it looks pretty random, which is generally what we want):
```{r, fig.height=6, fig.width=10, dev='CairoSVG'}
#lim is the only necessary additional argument -- it keeps ParticipantID from being split.
#lty makes all of the lines solid, line.type prevents a point from being drawn at the end
#of each line, and mxl spreads the replies out a little more.
splot(Canberra~reply*ParticipantID, su=Study==4, lim=FALSE, lty=1, line.type='l', mxl=c(1,2))
```

***
# Person Perception Ratings

After writing advice to the authors of each prompt, participants also completed ratings of the text and author.

One potentially interesting rating was of relative socioeconomic status (`relativeSes`; "Relative to your own, where would you place the author's socioeconomic status?"; -3 to 3).
```{r, fig.height=5, fig.width=10, dev='CairoSVG'}
#make a new variable to look at Study and Topic without Style.
Study_and_Topic = paste0('S', Study, ' ', Topic)

splot(relativeSes~Study_and_Topic*Style, type='bar')
```

A difference between styles doesn't appear in each topic, but when it does, the incongruent style is rated as lower in status than the congruent style (considering relational to be a feminine topic, and life course to be a masculine topic).

The inconsistency between prompts may be explained by setting; the first two life course prompts were largely job related, and the relational topics were not. The prompts in Study 4 set out to reverse this, with the relational topic set in a workplace, and the life course topic at least not directly related to a job.

It can sometimes help to look at the same pattern a different way, and compare it to that of other variables:
```{r, fig.height=6, fig.width=12, dev='CairoSVG'}
#levels reorders the prompt variable to make the trends a little easier to see.
splot(
  cbind(TextQuality, Behavioral, pp_like, relativeSes)~prompt, between=Study,
  mv.scale=T, levels=list(prompt=c(2,3,1,4))
)
```

In Study 3, each of the perception related variables seem to hang together for the most part, with ratings of the text (`TextQuality`), ratings of the author (`relativeSes`), and disposition toward the author (`pp_like` and `Behavioral`) all generally increasing from the masculine relational prompt to the masculine life course prompt. In contrast, in Study 4 only the SES rating remains similar, with liking staying the same between prompts, and text and quasi-behavioral ratings generally decreasing from the masculine relational to the masculine life course prompt.

Aside from being set it a workplace, the relational prompts in Study 4 also differed from the previous relational prompts in that their content was somewhat more striking (concerning a coworker's potential abuse of their autistic child). This may have influenced the perception of text quality in particular, as that appears to be the most aberrant of the perception ratings for those topics.

These are, of course, loose interpretations, but more exploration of the data may offer clearer pictures.

***
<div style='text-align:center'>
![Brought to you by the <a href="https://www.depts.ttu.edu/psy/lusi/resources.php" target="_blank">Language Use and Social Interaction</a> lab at Texas Tech University](https://www.depts.ttu.edu/psy/lusi/files/lusi.jpg)
</div>
